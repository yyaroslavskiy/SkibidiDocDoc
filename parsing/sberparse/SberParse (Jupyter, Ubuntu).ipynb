{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:39.923846Z",
     "start_time": "2025-11-04T00:52:39.211139Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bsaQ7ELRibr",
    "outputId": "bea2a63d-0f1e-483c-ee37-9eb0415ab79e"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:40.377791Z",
     "start_time": "2025-11-04T00:52:40.369571Z"
    },
    "id": "g1iVvomYdpYG"
   },
   "outputs": [],
   "source": [
    "def setup_logger(name='DocDocParser'): # логгирование\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if not logger.handlers:\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    \n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    \n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\"--lang=ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7\")\n",
    "    \n",
    "    user_agents = [\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    ]\n",
    "    chrome_options.add_argument(f\"--user-agent={random.choice(user_agents)}\")\n",
    "    \n",
    "    service = Service('/usr/bin/chromedriver')\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    # удаление webdriver свойств\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\n",
    "        \"userAgent\": driver.execute_script(\"return navigator.userAgent\")\n",
    "    })\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def is_valid_doctor_link(href): # проверка ссылок на корректность\n",
    "    if not href:\n",
    "        return False\n",
    "    if len(href.split('#')) > 1:\n",
    "        return False\n",
    "    match = re.search(r'/doctor/([A-ZА-Я][^/?]*)', href)\n",
    "    return match is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:41.197143Z",
     "start_time": "2025-11-04T00:52:41.173186Z"
    },
    "id": "ddmSgw7N4McA"
   },
   "outputs": [],
   "source": [
    "def parse_name(soup):\n",
    "    try:\n",
    "        name_elem = soup.find('div', {'data-testid': 'doctor__fio'})\n",
    "        return name_elem.text.strip() if name_elem else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_speciality(soup):\n",
    "    try:\n",
    "        speciality_container = soup.find('div', {'aria-label': 'Выбор специальности врача'})\n",
    "        if speciality_container:\n",
    "            speciality_spans = speciality_container.find_all('span', {'class': 'sdsClinicChip__t138vcdl sdsClinicChip__hhhycyd'})\n",
    "            if speciality_spans:\n",
    "                return ', '.join([x.text.strip() for x in speciality_spans])\n",
    "\n",
    "        speciality_elem = soup.find('li', {'data-testid': 'summary__speciality'})\n",
    "        if speciality_elem:\n",
    "            speciality_span = speciality_elem.find('span', {'class': 'tzjpv3j'})\n",
    "            return speciality_span.text.strip() if speciality_span else None\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def parse_clinics(soup):\n",
    "    clinics = []\n",
    "\n",
    "    try:\n",
    "        # Первый вариант - контейнер с выбором клиники\n",
    "        clinics_container = soup.find('div', {'aria-label': 'Выбор клиники'})\n",
    "        if clinics_container:\n",
    "            all_clinics = clinics_container.find_all('span', {'class': 'sdsClinicChip__c1yy1ila'})\n",
    "            for x in all_clinics:\n",
    "                name_elem = x.find('span', {'class': 'sdsClinicChip__t138vcdl sdsClinicChip__hhhycyd'})\n",
    "                address_elem = x.find('span', {'class': 'sdsClinicChip__s2rlal3 sdsClinicChip__hhhycyd'})\n",
    "                metro_elem = x.find('span', {'class': 'sdsSubway_13f0c476'})\n",
    "\n",
    "                clinics.append({\n",
    "                    'name': name_elem.text.strip() if name_elem else None,\n",
    "                    'address': address_elem.text.strip() if address_elem else None,\n",
    "                    'metro': metro_elem.text.strip() if metro_elem else None\n",
    "                })\n",
    "\n",
    "            if clinics:\n",
    "                return clinics\n",
    "\n",
    "        # Второй вариант - одиночная клиника\n",
    "        clinic = soup.find('div', {'data-testid': 'doctor-page__clinic'})\n",
    "        if clinic:\n",
    "            name_elem = clinic.find('a', {'data-testid': 'doctor-page__clinic-name'})\n",
    "            address_elem = clinic.find('div', {'data-testid': 'doctor-page__address-name'})\n",
    "            metro_elem = clinic.find('span', {'class': 'sdsSubway_a29aae9d'})\n",
    "\n",
    "            return [{\n",
    "                'name': name_elem.text.strip() if name_elem else None,\n",
    "                'address': address_elem.text.strip() if address_elem else None,\n",
    "                'metro': metro_elem.text.strip() if metro_elem else None\n",
    "            }]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return []\n",
    "\n",
    "def parse_price(soup):\n",
    "    try:\n",
    "        price_elems = [x.text.strip() for x in soup.find_all('div', {'data-testid': 'doctor-page__price-full'}) if '₽' in x.text]\n",
    "        if price_elems:\n",
    "            return price_elems[-1]\n",
    "\n",
    "        price_elems = [x.text.strip() for x in soup.find_all('div', {'data-testid': 'doctor-page__price-final'}) if '₽' in x.text]\n",
    "        if price_elems:\n",
    "            return price_elems[-1]\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def parse_experience(soup):\n",
    "    try:\n",
    "        experience_container = soup.find('div', {'data-testid': 'doctor__nameplate-experience'})\n",
    "        if experience_container:\n",
    "            experience_elem = experience_container.find('div', {'class': 't7amcxk'})\n",
    "            return experience_elem.text.strip() if experience_elem else None\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def parse_rating(soup):\n",
    "    try:\n",
    "        rating_container = soup.find('div', {'data-testid': 'doctor__rating-stars-mobile'})\n",
    "        if rating_container:\n",
    "            rating_elem = rating_container.find('span', {'class': 'sdsRatingStarsValue_695f7498'})\n",
    "            return rating_elem.text.strip() if rating_elem else None\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def parse_review_count(soup):\n",
    "    try:\n",
    "        review_container = soup.find('div', {'data-testid': 'doctor__nameplate-reviews-count'})\n",
    "        if review_container:\n",
    "            review_elem = review_container.find('div', {'class': 't7amcxk'})\n",
    "            if review_elem:\n",
    "                try:\n",
    "                    return int(re.search(r'\\d+', review_elem.text.strip()).group())\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def parse_reviews(soup, review_count):\n",
    "    if review_count <= 0:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        script_elem = soup.find('script', {'id': '__NEXT_DATA__'})\n",
    "        if script_elem:\n",
    "            data = json.loads(script_elem.text)\n",
    "            reviews_data = data.get('props', {}).get('pageProps', {}).get('preloadedState', {}).get('doctorPage', {}).get('doctor', {}).get('reviewsForSeo', [])\n",
    "\n",
    "            reviews = []\n",
    "            for review in reviews_data:\n",
    "                reviews.append({\n",
    "                    'rate': review.get('rating', {}).get('label', None),\n",
    "                    'date': review.get('date', None),\n",
    "                    'comment': review.get('text', None),\n",
    "                    'clinic': review.get('clinic', {}).get('name', None)\n",
    "                })\n",
    "\n",
    "            return reviews if reviews else None\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n",
    "def parse_patient_ages(soup):\n",
    "    kids = False\n",
    "    adults = False\n",
    "\n",
    "    try:\n",
    "        patients_container = soup.find('div', {'aria-label': 'Выбор возраста пациента'})\n",
    "        if patients_container:\n",
    "            patient_spans = patients_container.find_all('span', {'class': 'sdsClinicChip__t138vcdl sdsClinicChip__hhhycyd'})\n",
    "            patients_text = ''.join([x.text.lower() for x in patient_spans])\n",
    "            kids = 'дети' in patients_text\n",
    "            adults = 'взрослые' in patients_text\n",
    "            return kids, adults\n",
    "\n",
    "        age_elem = soup.find('li', {'data-testid': 'summary__age'})\n",
    "        if age_elem:\n",
    "            age_span = age_elem.find('span', {'class': 'tzjpv3j'})\n",
    "            if age_span:\n",
    "                patient_text = age_span.text.strip().lower()\n",
    "                kids = 'дети' in patient_text\n",
    "                adults = 'взрослые' in patient_text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return kids, adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:42.057978Z",
     "start_time": "2025-11-04T00:52:42.051708Z"
    },
    "id": "7Ax6tLgz4P14"
   },
   "outputs": [],
   "source": [
    "def parse_doctor(src, doctor_url):\n",
    "    soup = BeautifulSoup(src, \"lxml\")\n",
    "\n",
    "    name = parse_name(soup)\n",
    "    speciality = parse_speciality(soup)\n",
    "    clinics = parse_clinics(soup)\n",
    "    price = parse_price(soup)\n",
    "    experience = parse_experience(soup)\n",
    "    rating = parse_rating(soup)\n",
    "    review_count = parse_review_count(soup)\n",
    "    reviews = parse_reviews(soup, review_count)\n",
    "    kids, adults = parse_patient_ages(soup)\n",
    "\n",
    "    return {\n",
    "        'name': name,\n",
    "        'link': doctor_url,\n",
    "        'speciality': speciality,\n",
    "        'clinics': clinics if clinics else None,\n",
    "        'price': price,\n",
    "        'experience': experience,\n",
    "        'rating': rating,\n",
    "        'review_count': review_count,\n",
    "        'reviews': reviews,\n",
    "        'is_kids': kids,\n",
    "        'is_adults': adults\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:42.882615Z",
     "start_time": "2025-11-04T00:52:42.871650Z"
    },
    "id": "4DcJFBUV4WA_"
   },
   "outputs": [],
   "source": [
    "def get_doctor_links_from_page(driver, logger):\n",
    "    all_links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    seen_links = set()\n",
    "    doctor_links = []\n",
    "\n",
    "    for link in all_links:\n",
    "        try:\n",
    "            href = link.get_attribute('href')\n",
    "            if href and '/doctor/' in href:\n",
    "                normalized_href = href.split('#')[0].split('?')[0]\n",
    "                if normalized_href not in seen_links and is_valid_doctor_link(href):\n",
    "                    seen_links.add(normalized_href)\n",
    "                    doctor_links.append(href)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    logger.info(f\"Найдено валидных ссылок: {len(doctor_links)}\")\n",
    "    return doctor_links\n",
    "\n",
    "def get_next_page_link(driver):\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, 'button[data-testid=\"pagination-next\"]')\n",
    "        return next_button.get_attribute('href')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_doctors_on_page(driver, doctor_links, max_doctors_per_page, logger):\n",
    "    doctors_data = []\n",
    "    success_count = 0\n",
    "\n",
    "    doctors_to_parse = doctor_links[:max_doctors_per_page] if max_doctors_per_page else doctor_links\n",
    "\n",
    "    for i, doctor_url in enumerate(doctors_to_parse):\n",
    "        try:\n",
    "            driver.get(doctor_url)\n",
    "            time.sleep(1)\n",
    "\n",
    "            doctor_data = parse_doctor(driver.page_source, doctor_url)\n",
    "            doctors_data.append(doctor_data)\n",
    "            \n",
    "            with open('doctor_data.jsonl', 'a', encoding='utf-8') as f:\n",
    "                f.write(json.dumps(doctor_data, ensure_ascii=False) + '\\n')\n",
    "                \n",
    "            success_count += 1\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при парсинге врача {doctor_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "    logger.info(f\"Успешно спарсено врачей: {success_count}/{len(doctors_to_parse)}\")\n",
    "    return doctors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:43.651830Z",
     "start_time": "2025-11-04T00:52:43.638992Z"
    },
    "id": "iN--SQ2K4Z3Z"
   },
   "outputs": [],
   "source": [
    "def prepare_csv_data(doctors_data):\n",
    "    csv_data = []\n",
    "\n",
    "    for doctor in doctors_data:\n",
    "        row = {\n",
    "            'name': doctor.get('name', None),\n",
    "            'speciality': doctor.get('speciality', None),\n",
    "            'experience': doctor.get('experience', None),\n",
    "            'rating': doctor.get('rating', None),\n",
    "            'review_count': doctor.get('review_count', 0),\n",
    "            'price': doctor.get('price', None),\n",
    "            'is_kids': doctor.get('is_kids', False),\n",
    "            'is_adults': doctor.get('is_adults', False),\n",
    "            'link': doctor.get('link', None),\n",
    "            'clinics_count': len(doctor.get('clinics', [])) if doctor.get('clinics', []) else 0,\n",
    "        }\n",
    "\n",
    "        clinics = doctor.get('clinics', [])\n",
    "        for i, clinic in enumerate(clinics[:3]):\n",
    "            row[f'clinic_{i+1}_name'] = clinic.get('name', None)\n",
    "            row[f'clinic_{i+1}_address'] = clinic.get('address', None)\n",
    "            row[f'clinic_{i+1}_metro'] = clinic.get('metro', None)\n",
    "\n",
    "        for i in range(len(clinics), 3):\n",
    "            row[f'clinic_{i+1}_name'] = None\n",
    "            row[f'clinic_{i+1}_address'] = None\n",
    "            row[f'clinic_{i+1}_metro'] = None\n",
    "\n",
    "        csv_data.append(row)\n",
    "\n",
    "    return csv_data\n",
    "\n",
    "def save_to_dataset(doctors_data, filename_prefix, logger):\n",
    "    if not doctors_data:\n",
    "        if logger:\n",
    "            logger.info(\"Ошибка: нет данных для сохранения\")\n",
    "        return None\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    json_filename = f\"{filename_prefix}_{timestamp}.json\"\n",
    "    with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(doctors_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    if logger:\n",
    "        logger.info(f\"Полные данные сохранены в {json_filename}\")\n",
    "\n",
    "    csv_data = prepare_csv_data(doctors_data)\n",
    "    csv_filename = f\"{filename_prefix}_{timestamp}.csv\"\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    if logger:\n",
    "        logger.info(f\"Датасет сохранен в {csv_filename}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:44.447673Z",
     "start_time": "2025-11-04T00:52:44.435559Z"
    },
    "id": "F0A64rIU4c1l"
   },
   "outputs": [],
   "source": [
    "class SeleniumDocDocParser:\n",
    "    def __init__(self, start = 0):\n",
    "        self.base_url = \"https://docdoc.ru\"\n",
    "        self.doctors_url = \"https://docdoc.ru/doctor/endokrinolog\" # Изначальная ссылка\n",
    "        self.doctors_data = []\n",
    "        self.logger = setup_logger('DocDocParser')\n",
    "        self.start = start\n",
    "\n",
    "    def setup_driver(self):\n",
    "        return setup_driver()\n",
    "\n",
    "    def parse_doctor(self, src, doctor_url):\n",
    "        return parse_doctor(src, doctor_url)\n",
    "\n",
    "    def is_valid_doctor_link(self, href):\n",
    "        return is_valid_doctor_link(href)\n",
    "\n",
    "    def get_doctor_links_from_page(self, driver):\n",
    "        return get_doctor_links_from_page(driver, self.logger)\n",
    "\n",
    "    def get_next_page_link(self, driver):\n",
    "        return get_next_page_link(driver)\n",
    "\n",
    "    def save_to_dataset(self, filename_prefix='doctors'):\n",
    "        return save_to_dataset(self.doctors_data, filename_prefix, self.logger)\n",
    "\n",
    "    def parse_multiple_pages(self, max_pages=1, max_doctors_per_page=None):\n",
    "        driver = self.setup_driver()\n",
    "        page_count = 0\n",
    "\n",
    "        try:\n",
    "            self.logger.info(\"Parsing started.\")\n",
    "\n",
    "            while page_count < max_pages:\n",
    "                page_count += 1\n",
    "                current_url = f\"{self.doctors_url}/page/{page_count + self.start}\"\n",
    "                self.logger.info(f\"Page {page_count + self.start} loading...\")\n",
    "                self.logger.info(f\"URL: {current_url}\")\n",
    "\n",
    "                driver.get(current_url)\n",
    "                time.sleep(1)\n",
    "\n",
    "                self.logger.info(\"Searching the links\")\n",
    "                doctor_links = self.get_doctor_links_from_page(driver)\n",
    "\n",
    "                if not doctor_links:\n",
    "                    self.logger.info(f\"Не найдено валидных ссылок на врачей. Переход к следующей странице.\")\n",
    "                    continue\n",
    "\n",
    "                # Парсим врачей с текущей страницы\n",
    "                self.logger.info(f\"Парсинг врачей на странице {page_count}...\")\n",
    "                page_doctors_data = parse_doctors_on_page(\n",
    "                    driver, doctor_links, max_doctors_per_page, self.logger\n",
    "                )\n",
    "                self.doctors_data.extend(page_doctors_data)\n",
    "\n",
    "            # Сохраняем все собранные данные\n",
    "            self.logger.info(f\"Сохраненяем все собранные данные ({len(self.doctors_data)} записей)...\")\n",
    "            if self.doctors_data:\n",
    "                self.save_to_dataset('doctors'+str(self.start))\n",
    "                self.logger.info(\"Парсинг завершён!\")\n",
    "                self.logger.info(f\"Всего считано врачей: {len(self.doctors_data)}\")\n",
    "            else:\n",
    "                self.logger.info(\"Ошибка парсинга: врачи отсутствуют\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Ошибка во время парсинга: {e}\")\n",
    "        finally:\n",
    "            driver.quit()\n",
    "            self.logger.info(\"Браузер закрыт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T05:19:43.491206Z",
     "start_time": "2025-11-04T00:52:46.825784Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fec18be",
    "outputId": "4ed7f6d1-343b-40fd-b469-fe594b75a550"
   },
   "outputs": [],
   "source": [
    "parser = SeleniumDocDocParser(51) # В скобки номер страницы\n",
    "parser.parse_multiple_pages(max_pages=82, max_doctors_per_page=21) # В первый параметр количество страниц"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
