{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:39.923846Z",
     "start_time": "2025-11-04T00:52:39.211139Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bsaQ7ELRibr",
    "outputId": "bea2a63d-0f1e-483c-ee37-9eb0415ab79e"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:40.377791Z",
     "start_time": "2025-11-04T00:52:40.369571Z"
    },
    "id": "g1iVvomYdpYG"
   },
   "outputs": [],
   "source": [
    "def setup_logger(name='DocDocParser'): # логгирование\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if not logger.handlers:\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    \n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    \n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\"--lang=ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7\")\n",
    "    \n",
    "    user_agents = [\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    ]\n",
    "    chrome_options.add_argument(f\"--user-agent={random.choice(user_agents)}\")\n",
    "    \n",
    "    service = Service('/usr/bin/chromedriver')\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    # удаление webdriver свойств\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\n",
    "        \"userAgent\": driver.execute_script(\"return navigator.userAgent\")\n",
    "    })\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def is_valid_doctor_link(href): # проверка ссылок на корректность\n",
    "    if not href:\n",
    "        return False\n",
    "    if len(href.split('#')) > 1:\n",
    "        return False\n",
    "    match = re.search(r'/doctor/([A-ZА-Я][^/?]*)', href)\n",
    "    return match is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:41.197143Z",
     "start_time": "2025-11-04T00:52:41.173186Z"
    },
    "id": "ddmSgw7N4McA"
   },
   "outputs": [],
   "source": [
    "def parse_name(soup):\n",
    "    try:\n",
    "        name_elem = soup.find('div', {'data-testid': 'doctor__fio'})\n",
    "        return name_elem.text.strip() if name_elem else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_speciality(soup):\n",
    "    try:\n",
    "        speciality_container = soup.find('div', {'aria-label': 'Выбор специальности врача'})\n",
    "        if speciality_container:\n",
    "            speciality_spans = speciality_container.find_all('span', {'class': 'sdsClinicChip__t138vcdl sdsClinicChip__hhhycyd'})\n",
    "            if speciality_spans:\n",
    "                return ', '.join([x.text.strip() for x in speciality_spans])\n",
    "\n",
    "        speciality_elem = soup.find('li', {'data-testid': 'summary__speciality'})\n",
    "        if speciality_elem:\n",
    "            speciality_span = speciality_elem.find('span', {'class': 'tzjpv3j'})\n",
    "            return speciality_span.text.strip() if speciality_span else None\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def parse_clinics(soup):\n",
    "    clinics = []\n",
    "\n",
    "    try:\n",
    "        # Первый вариант - контейнер с выбором клиники\n",
    "        clinics_container = soup.find('div', {'aria-label': 'Выбор клиники'})\n",
    "        if clinics_container:\n",
    "            all_clinics = clinics_container.find_all('span', {'class': 'sdsClinicChip__c1yy1ila'})\n",
    "            for x in all_clinics:\n",
    "                name_elem = x.find('span', {'class': 'sdsClinicChip__t138vcdl sdsClinicChip__hhhycyd'})\n",
    "                address_elem = x.find('span', {'class': 'sdsClinicChip__s2rlal3 sdsClinicChip__hhhycyd'})\n",
    "                metro_elem = x.find('span', {'class': 'sdsSubway_13f0c476'})\n",
    "\n",
    "                clinics.append({\n",
    "                    'name': name_elem.text.strip() if name_elem else None,\n",
    "                    'address': address_elem.text.strip() if address_elem else None,\n",
    "                    'metro': metro_elem.text.strip() if metro_elem else None\n",
    "                })\n",
    "\n",
    "            if clinics:\n",
    "                return clinics\n",
    "\n",
    "        # Второй вариант - одиночная клиника\n",
    "        clinic = soup.find('div', {'data-testid': 'doctor-page__clinic'})\n",
    "        if clinic:\n",
    "            name_elem = clinic.find('a', {'data-testid': 'doctor-page__clinic-name'})\n",
    "            address_elem = clinic.find('div', {'data-testid': 'doctor-page__address-name'})\n",
    "            metro_elem = clinic.find('span', {'class': 'sdsSubway_a29aae9d'})\n",
    "\n",
    "            return [{\n",
    "                'name': name_elem.text.strip() if name_elem else None,\n",
    "                'address': address_elem.text.strip() if address_elem else None,\n",
    "                'metro': metro_elem.text.strip() if metro_elem else None\n",
    "            }]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return []\n",
    "\n",
    "def parse_price(soup):\n",
    "    try:\n",
    "        price_elems = [x.text.strip() for x in soup.find_all('div', {'data-testid': 'doctor-page__price-full'}) if '₽' in x.text]\n",
    "        if price_elems:\n",
    "            return price_elems[-1]\n",
    "\n",
    "        price_elems = [x.text.strip() for x in soup.find_all('div', {'data-testid': 'doctor-page__price-final'}) if '₽' in x.text]\n",
    "        if price_elems:\n",
    "            return price_elems[-1]\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def parse_experience(soup):\n",
    "    try:\n",
    "        experience_container = soup.find('div', {'data-testid': 'doctor__nameplate-experience'})\n",
    "        if experience_container:\n",
    "            experience_elem = experience_container.find('div', {'class': 't7amcxk'})\n",
    "            return experience_elem.text.strip() if experience_elem else None\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def parse_rating(soup):\n",
    "    try:\n",
    "        rating_container = soup.find('div', {'data-testid': 'doctor__rating-stars-mobile'})\n",
    "        if rating_container:\n",
    "            rating_elem = rating_container.find('span', {'class': 'sdsRatingStarsValue_695f7498'})\n",
    "            return rating_elem.text.strip() if rating_elem else None\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def parse_review_count(soup):\n",
    "    try:\n",
    "        review_container = soup.find('div', {'data-testid': 'doctor__nameplate-reviews-count'})\n",
    "        if review_container:\n",
    "            review_elem = review_container.find('div', {'class': 't7amcxk'})\n",
    "            if review_elem:\n",
    "                try:\n",
    "                    return int(re.search(r'\\d+', review_elem.text.strip()).group())\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def parse_reviews(soup, review_count):\n",
    "    if review_count <= 0:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        script_elem = soup.find('script', {'id': '__NEXT_DATA__'})\n",
    "        if script_elem:\n",
    "            data = json.loads(script_elem.text)\n",
    "            reviews_data = data.get('props', {}).get('pageProps', {}).get('preloadedState', {}).get('doctorPage', {}).get('doctor', {}).get('reviewsForSeo', [])\n",
    "\n",
    "            reviews = []\n",
    "            for review in reviews_data:\n",
    "                reviews.append({\n",
    "                    'rate': review.get('rating', {}).get('label', None),\n",
    "                    'date': review.get('date', None),\n",
    "                    'comment': review.get('text', None),\n",
    "                    'clinic': review.get('clinic', {}).get('name', None)\n",
    "                })\n",
    "\n",
    "            return reviews if reviews else None\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n",
    "def parse_patient_ages(soup):\n",
    "    kids = False\n",
    "    adults = False\n",
    "\n",
    "    try:\n",
    "        patients_container = soup.find('div', {'aria-label': 'Выбор возраста пациента'})\n",
    "        if patients_container:\n",
    "            patient_spans = patients_container.find_all('span', {'class': 'sdsClinicChip__t138vcdl sdsClinicChip__hhhycyd'})\n",
    "            patients_text = ''.join([x.text.lower() for x in patient_spans])\n",
    "            kids = 'дети' in patients_text\n",
    "            adults = 'взрослые' in patients_text\n",
    "            return kids, adults\n",
    "\n",
    "        age_elem = soup.find('li', {'data-testid': 'summary__age'})\n",
    "        if age_elem:\n",
    "            age_span = age_elem.find('span', {'class': 'tzjpv3j'})\n",
    "            if age_span:\n",
    "                patient_text = age_span.text.strip().lower()\n",
    "                kids = 'дети' in patient_text\n",
    "                adults = 'взрослые' in patient_text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return kids, adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:42.057978Z",
     "start_time": "2025-11-04T00:52:42.051708Z"
    },
    "id": "7Ax6tLgz4P14"
   },
   "outputs": [],
   "source": [
    "def parse_doctor(src, doctor_url):\n",
    "    soup = BeautifulSoup(src, \"lxml\")\n",
    "\n",
    "    name = parse_name(soup)\n",
    "    speciality = parse_speciality(soup)\n",
    "    clinics = parse_clinics(soup)\n",
    "    price = parse_price(soup)\n",
    "    experience = parse_experience(soup)\n",
    "    rating = parse_rating(soup)\n",
    "    review_count = parse_review_count(soup)\n",
    "    reviews = parse_reviews(soup, review_count)\n",
    "    kids, adults = parse_patient_ages(soup)\n",
    "\n",
    "    return {\n",
    "        'name': name,\n",
    "        'link': doctor_url,\n",
    "        'speciality': speciality,\n",
    "        'clinics': clinics if clinics else None,\n",
    "        'price': price,\n",
    "        'experience': experience,\n",
    "        'rating': rating,\n",
    "        'review_count': review_count,\n",
    "        'reviews': reviews,\n",
    "        'is_kids': kids,\n",
    "        'is_adults': adults\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:42.882615Z",
     "start_time": "2025-11-04T00:52:42.871650Z"
    },
    "id": "4DcJFBUV4WA_"
   },
   "outputs": [],
   "source": [
    "def get_doctor_links_from_page(driver, logger):\n",
    "    all_links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    seen_links = set()\n",
    "    doctor_links = []\n",
    "\n",
    "    for link in all_links:\n",
    "        try:\n",
    "            href = link.get_attribute('href')\n",
    "            if href and '/doctor/' in href:\n",
    "                normalized_href = href.split('#')[0].split('?')[0]\n",
    "                if normalized_href not in seen_links and is_valid_doctor_link(href):\n",
    "                    seen_links.add(normalized_href)\n",
    "                    doctor_links.append(href)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    logger.info(f\"Найдено валидных ссылок: {len(doctor_links)}\")\n",
    "    return doctor_links\n",
    "\n",
    "def get_next_page_link(driver):\n",
    "    try:\n",
    "        next_button = driver.find_element(By.CSS_SELECTOR, 'button[data-testid=\"pagination-next\"]')\n",
    "        return next_button.get_attribute('href')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_doctors_on_page(driver, doctor_links, max_doctors_per_page, logger):\n",
    "    doctors_data = []\n",
    "    success_count = 0\n",
    "\n",
    "    doctors_to_parse = doctor_links[:max_doctors_per_page] if max_doctors_per_page else doctor_links\n",
    "\n",
    "    for i, doctor_url in enumerate(doctors_to_parse):\n",
    "        try:\n",
    "            driver.get(doctor_url)\n",
    "            time.sleep(1)\n",
    "\n",
    "            doctor_data = parse_doctor(driver.page_source, doctor_url)\n",
    "            doctors_data.append(doctor_data)\n",
    "            \n",
    "            with open('doctor_data.jsonl', 'a', encoding='utf-8') as f:\n",
    "                f.write(json.dumps(doctor_data, ensure_ascii=False) + '\\n')\n",
    "                \n",
    "            success_count += 1\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Ошибка при парсинге врача {doctor_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "    logger.info(f\"Успешно спарсено врачей: {success_count}/{len(doctors_to_parse)}\")\n",
    "    return doctors_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:43.651830Z",
     "start_time": "2025-11-04T00:52:43.638992Z"
    },
    "id": "iN--SQ2K4Z3Z"
   },
   "outputs": [],
   "source": [
    "def prepare_csv_data(doctors_data):\n",
    "    csv_data = []\n",
    "\n",
    "    for doctor in doctors_data:\n",
    "        row = {\n",
    "            'name': doctor.get('name', None),\n",
    "            'speciality': doctor.get('speciality', None),\n",
    "            'experience': doctor.get('experience', None),\n",
    "            'rating': doctor.get('rating', None),\n",
    "            'review_count': doctor.get('review_count', 0),\n",
    "            'price': doctor.get('price', None),\n",
    "            'is_kids': doctor.get('is_kids', False),\n",
    "            'is_adults': doctor.get('is_adults', False),\n",
    "            'link': doctor.get('link', None),\n",
    "            'clinics_count': len(doctor.get('clinics', [])) if doctor.get('clinics', []) else 0,\n",
    "        }\n",
    "\n",
    "        clinics = doctor.get('clinics', [])\n",
    "        for i, clinic in enumerate(clinics[:3]):\n",
    "            row[f'clinic_{i+1}_name'] = clinic.get('name', None)\n",
    "            row[f'clinic_{i+1}_address'] = clinic.get('address', None)\n",
    "            row[f'clinic_{i+1}_metro'] = clinic.get('metro', None)\n",
    "\n",
    "        for i in range(len(clinics), 3):\n",
    "            row[f'clinic_{i+1}_name'] = None\n",
    "            row[f'clinic_{i+1}_address'] = None\n",
    "            row[f'clinic_{i+1}_metro'] = None\n",
    "\n",
    "        csv_data.append(row)\n",
    "\n",
    "    return csv_data\n",
    "\n",
    "def save_to_dataset(doctors_data, filename_prefix, logger):\n",
    "    if not doctors_data:\n",
    "        if logger:\n",
    "            logger.info(\"Ошибка: нет данных для сохранения\")\n",
    "        return None\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    json_filename = f\"{filename_prefix}_{timestamp}.json\"\n",
    "    with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(doctors_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    if logger:\n",
    "        logger.info(f\"Полные данные сохранены в {json_filename}\")\n",
    "\n",
    "    csv_data = prepare_csv_data(doctors_data)\n",
    "    csv_filename = f\"{filename_prefix}_{timestamp}.csv\"\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    if logger:\n",
    "        logger.info(f\"Датасет сохранен в {csv_filename}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T00:52:44.447673Z",
     "start_time": "2025-11-04T00:52:44.435559Z"
    },
    "id": "F0A64rIU4c1l"
   },
   "outputs": [],
   "source": [
    "class SeleniumDocDocParser:\n",
    "    def __init__(self, start = 0):\n",
    "        self.base_url = \"https://docdoc.ru\"\n",
    "        self.doctors_url = \"https://docdoc.ru/doctor/endokrinolog\" # Изначальная ссылка\n",
    "        self.doctors_data = []\n",
    "        self.logger = setup_logger('DocDocParser')\n",
    "        self.start = start\n",
    "\n",
    "    def setup_driver(self):\n",
    "        return setup_driver()\n",
    "\n",
    "    def parse_doctor(self, src, doctor_url):\n",
    "        return parse_doctor(src, doctor_url)\n",
    "\n",
    "    def is_valid_doctor_link(self, href):\n",
    "        return is_valid_doctor_link(href)\n",
    "\n",
    "    def get_doctor_links_from_page(self, driver):\n",
    "        return get_doctor_links_from_page(driver, self.logger)\n",
    "\n",
    "    def get_next_page_link(self, driver):\n",
    "        return get_next_page_link(driver)\n",
    "\n",
    "    def save_to_dataset(self, filename_prefix='doctors'):\n",
    "        return save_to_dataset(self.doctors_data, filename_prefix, self.logger)\n",
    "\n",
    "    def parse_multiple_pages(self, max_pages=1, max_doctors_per_page=None):\n",
    "        driver = self.setup_driver()\n",
    "        page_count = 0\n",
    "\n",
    "        try:\n",
    "            self.logger.info(\"Parsing started.\")\n",
    "\n",
    "            while page_count < max_pages:\n",
    "                page_count += 1\n",
    "                current_url = f\"{self.doctors_url}/page/{page_count + self.start}\"\n",
    "                self.logger.info(f\"Page {page_count + self.start} loading...\")\n",
    "                self.logger.info(f\"URL: {current_url}\")\n",
    "\n",
    "                driver.get(current_url)\n",
    "                time.sleep(1)\n",
    "\n",
    "                self.logger.info(\"Searching the links\")\n",
    "                doctor_links = self.get_doctor_links_from_page(driver)\n",
    "\n",
    "                if not doctor_links:\n",
    "                    self.logger.info(f\"Не найдено валидных ссылок на врачей. Переход к следующей странице.\")\n",
    "                    continue\n",
    "\n",
    "                # Парсим врачей с текущей страницы\n",
    "                self.logger.info(f\"Парсинг врачей на странице {page_count}...\")\n",
    "                page_doctors_data = parse_doctors_on_page(\n",
    "                    driver, doctor_links, max_doctors_per_page, self.logger\n",
    "                )\n",
    "                self.doctors_data.extend(page_doctors_data)\n",
    "\n",
    "            # Сохраняем все собранные данные\n",
    "            self.logger.info(f\"Сохраненяем все собранные данные ({len(self.doctors_data)} записей)...\")\n",
    "            if self.doctors_data:\n",
    "                self.save_to_dataset('doctors'+str(self.start))\n",
    "                self.logger.info(\"Парсинг завершён!\")\n",
    "                self.logger.info(f\"Всего считано врачей: {len(self.doctors_data)}\")\n",
    "            else:\n",
    "                self.logger.info(\"Ошибка парсинга: врачи отсутствуют\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Ошибка во время парсинга: {e}\")\n",
    "        finally:\n",
    "            driver.quit()\n",
    "            self.logger.info(\"Браузер закрыт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T05:19:43.491206Z",
     "start_time": "2025-11-04T00:52:46.825784Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0fec18be",
    "outputId": "4ed7f6d1-343b-40fd-b469-fe594b75a550"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 21:56:46,015 - INFO -  Parsing started.\n",
      "2025-11-04 21:56:46,023 - INFO - \n",
      "Page 37 loading...\n",
      "2025-11-04 21:56:46,030 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/37\n",
      "2025-11-04 22:02:01,412 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:02:14,182 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:02:14,185 - INFO -  Парсинг врачей (максимум 21) на странице 1...\n",
      "2025-11-04 22:05:46,994 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:05:47,001 - INFO - \n",
      "Page 38 loading...\n",
      "2025-11-04 22:05:47,005 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/38\n",
      "2025-11-04 22:05:51,612 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:05:54,754 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:05:54,756 - INFO -  Парсинг врачей (максимум 21) на странице 2...\n",
      "2025-11-04 22:10:41,908 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:10:41,912 - INFO - \n",
      "Page 39 loading...\n",
      "2025-11-04 22:10:41,920 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/39\n",
      "2025-11-04 22:10:50,561 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:10:58,445 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:10:58,447 - INFO -  Парсинг врачей (максимум 21) на странице 3...\n",
      "2025-11-04 22:18:35,996 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:18:36,005 - INFO - \n",
      "Page 40 loading...\n",
      "2025-11-04 22:18:36,007 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/40\n",
      "2025-11-04 22:18:44,114 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:18:51,072 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:18:51,075 - INFO -  Парсинг врачей (максимум 21) на странице 4...\n",
      "2025-11-04 22:25:59,675 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:25:59,676 - INFO - \n",
      "Page 41 loading...\n",
      "2025-11-04 22:25:59,677 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/41\n",
      "2025-11-04 22:26:03,414 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:26:04,731 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:26:04,733 - INFO -  Парсинг врачей (максимум 21) на странице 5...\n",
      "2025-11-04 22:28:28,047 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:28:28,048 - INFO - \n",
      "Page 42 loading...\n",
      "2025-11-04 22:28:28,049 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/42\n",
      "2025-11-04 22:28:31,147 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:28:32,349 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:28:32,350 - INFO -  Парсинг врачей (максимум 21) на странице 6...\n",
      "2025-11-04 22:30:49,698 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:30:49,699 - INFO - \n",
      "Page 43 loading...\n",
      "2025-11-04 22:30:49,700 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/43\n",
      "2025-11-04 22:30:53,261 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:30:56,073 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:30:56,074 - INFO -  Парсинг врачей (максимум 21) на странице 7...\n",
      "2025-11-04 22:34:36,620 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:34:36,623 - INFO - \n",
      "Page 44 loading...\n",
      "2025-11-04 22:34:36,625 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/44\n",
      "2025-11-04 22:34:44,842 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:34:53,243 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:34:53,243 - INFO -  Парсинг врачей (максимум 21) на странице 8...\n",
      "2025-11-04 22:37:23,654 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:37:23,655 - INFO - \n",
      "Page 45 loading...\n",
      "2025-11-04 22:37:23,656 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/45\n",
      "2025-11-04 22:37:27,991 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:37:29,539 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:37:29,540 - INFO -  Парсинг врачей (максимум 21) на странице 9...\n",
      "2025-11-04 22:39:48,884 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:39:48,886 - INFO - \n",
      "Page 46 loading...\n",
      "2025-11-04 22:39:48,888 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/46\n",
      "2025-11-04 22:39:51,639 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:39:51,712 - INFO - Найдено валидных ссылок: 0\n",
      "2025-11-04 22:39:51,713 - INFO -  Не найдено валидных ссылок на врачей. Переход к следующей странице.\n",
      "2025-11-04 22:39:51,717 - INFO - \n",
      "Page 47 loading...\n",
      "2025-11-04 22:39:51,724 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/47\n",
      "2025-11-04 22:39:54,527 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:39:54,628 - INFO - Найдено валидных ссылок: 0\n",
      "2025-11-04 22:39:54,629 - INFO -  Не найдено валидных ссылок на врачей. Переход к следующей странице.\n",
      "2025-11-04 22:39:54,631 - INFO - \n",
      "Page 48 loading...\n",
      "2025-11-04 22:39:54,632 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/48\n",
      "2025-11-04 22:39:57,343 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:39:57,454 - INFO - Найдено валидных ссылок: 0\n",
      "2025-11-04 22:39:57,456 - INFO -  Не найдено валидных ссылок на врачей. Переход к следующей странице.\n",
      "2025-11-04 22:39:57,456 - INFO - \n",
      "Page 49 loading...\n",
      "2025-11-04 22:39:57,458 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/49\n",
      "2025-11-04 22:40:00,173 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:40:04,338 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:40:04,338 - INFO -  Парсинг врачей (максимум 21) на странице 13...\n",
      "2025-11-04 22:42:46,665 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:42:46,666 - INFO - \n",
      "Page 50 loading...\n",
      "2025-11-04 22:42:46,670 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/50\n",
      "2025-11-04 22:42:51,766 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:42:54,800 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:42:54,804 - INFO -  Парсинг врачей (максимум 21) на странице 14...\n",
      "2025-11-04 22:46:48,202 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:46:48,204 - INFO - \n",
      "Page 51 loading...\n",
      "2025-11-04 22:46:48,205 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/51\n",
      "2025-11-04 22:46:54,490 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:47:01,740 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:47:01,744 - INFO -  Парсинг врачей (максимум 21) на странице 15...\n",
      "2025-11-04 22:50:45,553 - INFO - Успешно спарсено врачей: 20/20\n",
      "2025-11-04 22:50:45,554 - INFO - \n",
      "Page 52 loading...\n",
      "2025-11-04 22:50:45,554 - INFO -    URL: https://docdoc.ru/doctor/endokrinolog/page/52\n",
      "2025-11-04 22:50:50,004 - INFO - \n",
      "Searching the links\n",
      "2025-11-04 22:50:51,447 - INFO - Найдено валидных ссылок: 20\n",
      "2025-11-04 22:50:51,448 - INFO -  Парсинг врачей (максимум 21) на странице 16...\n",
      "2025-11-04 22:53:09,662 - INFO -  Браузер закрыт\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m parser \u001b[38;5;241m=\u001b[39m SeleniumDocDocParser(\u001b[38;5;241m36\u001b[39m) \u001b[38;5;66;03m# В скобки номер страницы\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_multiple_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m132\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_doctors_per_page\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m21\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# В первый параметр количество страниц\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[49], line 52\u001b[0m, in \u001b[0;36mSeleniumDocDocParser.parse_multiple_pages\u001b[0;34m(self, max_pages, max_doctors_per_page)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Парсим врачей с текущей страницы\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Парсинг врачей (максимум \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_doctors_per_page\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mmax_doctors_per_page\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mвсе\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) на странице \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m     page_doctors_data \u001b[38;5;241m=\u001b[39m \u001b[43mparse_doctors_on_page\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctor_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_doctors_per_page\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoctors_data\u001b[38;5;241m.\u001b[39mextend(page_doctors_data)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Сохраняем все собранные данные\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[44], line 39\u001b[0m, in \u001b[0;36mparse_doctors_on_page\u001b[0;34m(driver, doctor_links, max_doctors_per_page, logger)\u001b[0m\n\u001b[1;32m     36\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(doctor_url)\n\u001b[1;32m     37\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m doctor_data \u001b[38;5;241m=\u001b[39m \u001b[43mparse_doctor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoctor_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m doctors_data\u001b[38;5;241m.\u001b[39mappend(doctor_data)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoctor_data.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m, in \u001b[0;36mparse_doctor\u001b[0;34m(src, doctor_url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_doctor\u001b[39m(src, doctor_url):\n\u001b[0;32m----> 2\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Парсим все данные используя отдельные функции\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     name \u001b[38;5;241m=\u001b[39m parse_name(soup)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/bs4/__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/bs4/__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/bs4/builder/_lxml.py:380\u001b[0m, in \u001b[0;36mLXMLTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser_for(encoding)\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m, \u001b[38;5;167;01mLookupError\u001b[39;00m, etree\u001b[38;5;241m.\u001b[39mParserError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32msrc/lxml/parser.pxi:1331\u001b[0m, in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/parser.pxi:1451\u001b[0m, in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/parsertarget.pxi:161\u001b[0m, in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/parsertarget.pxi:156\u001b[0m, in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/etree.pyx:329\u001b[0m, in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/saxparser.pxi:451\u001b[0m, in \u001b[0;36mlxml.etree._handleSaxTargetStartNoNs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/saxparser.pxi:466\u001b[0m, in \u001b[0;36mlxml.etree._callTargetSaxStart\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/lxml/parsertarget.pxi:94\u001b[0m, in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxStart\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/bs4/builder/_lxml.py:303\u001b[0m, in \u001b[0;36mLXMLTreeBuilderForXML.start\u001b[0;34m(self, name, attrs, nsmap)\u001b[0m\n\u001b[1;32m    301\u001b[0m namespace, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getNsTag(name)\n\u001b[1;32m    302\u001b[0m nsprefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefix_for_namespace(namespace)\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_starttag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_namespace_prefixes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/bs4/__init__.py:749\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagStack) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    746\u001b[0m          \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only\u001b[38;5;241m.\u001b[39msearch_tag(name, attrs))):\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 749\u001b[0m tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_classes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTag\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrentTag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_most_recent_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43msourceline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourceline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msourcepos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msourcepos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespaces\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tag\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/bs4/element.py:1262\u001b[0m, in \u001b[0;36mTag.__init__\u001b[0;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous, is_xml, sourceline, sourcepos, can_be_empty_element, cdata_list_attributes, preserve_whitespace_tags, interesting_string_types, namespaces)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attrs:\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m builder\u001b[38;5;241m.\u001b[39mcdata_list_attributes:\n\u001b[0;32m-> 1262\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_replace_cdata_list_attribute_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(attrs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/bs4/builder/__init__.py:313\u001b[0m, in \u001b[0;36mTreeBuilder._replace_cdata_list_attribute_values\u001b[0;34m(self, tag_name, attrs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcdata_list_attributes:\n\u001b[1;32m    311\u001b[0m     universal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcdata_list_attributes\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m    312\u001b[0m     tag_specific \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcdata_list_attributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m--> 313\u001b[0m         \u001b[43mtag_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(attrs\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m universal \u001b[38;5;129;01mor\u001b[39;00m (tag_specific \u001b[38;5;129;01mand\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m tag_specific):\n\u001b[1;32m    316\u001b[0m             \u001b[38;5;66;03m# We have a \"class\"-type attribute whose string\u001b[39;00m\n\u001b[1;32m    317\u001b[0m             \u001b[38;5;66;03m# value is a whitespace-separated list of\u001b[39;00m\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;66;03m# values. Split it into a list.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser = SeleniumDocDocParser(51) # В скобки номер страницы\n",
    "parser.parse_multiple_pages(max_pages=82, max_doctors_per_page=21) # В первый параметр количество страниц"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
