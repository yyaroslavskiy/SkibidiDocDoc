{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lkp3ndXxjjE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/doctors'\n",
        "doctors_data = load_folder(folder_path)"
      ],
      "metadata": {
        "id": "tkjuRgEahawl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_single_file(file_path):\n",
        "    \"\"\"\n",
        "    Обрабатывает один JSON или JSONL файл и возвращает список словарей\n",
        "    \"\"\"\n",
        "    data_list = []\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f: # открываем файл для чтения с кодировкой UTF-8\n",
        "            if file_path.endswith('.jsonl'):\n",
        "                for line in f: # жля JSONL файлов читаем файл построчно\n",
        "                    line = line.strip()\n",
        "                    if line:\n",
        "                        data = json.loads(line) # преобразуем строку JSON в объект Python\n",
        "                        if isinstance(data, dict): # проверяем является ли data словарем\n",
        "                            data_list.append(data) # если да, то добавляем в список\n",
        "                        elif isinstance(data, list):\n",
        "                            data_list.extend(data) # если нет, то мы как бы распаковываем и добавляем в спиок (например, если у нас было два словаря в списке)\n",
        "            else: # аналогично, но без построчной обработки, так как это JSON\n",
        "                data = json.load(f)\n",
        "                if isinstance(data, dict):\n",
        "                    data_list.append(data)\n",
        "                elif isinstance(data, list):\n",
        "                    data_list.extend(data)\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка в файле {file_path}: {str(e)}\")\n",
        "    return data_list"
      ],
      "metadata": {
        "id": "69Rq4_pA0pM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_folder(folder_path):\n",
        "    all_data = []\n",
        "\n",
        "    for file in os.listdir(folder_path): # получаем список всех файлов и папок в указанной директории\n",
        "        if file.endswith(('.json', '.jsonl')):\n",
        "            file_path = os.path.join(folder_path, file) # создаем полный путь к файлу\n",
        "            all_data.extend(process_single_file(file_path)) # добавляем все обработанные файлы в общий список (extend тк \"распаковываем\" список и добавляем его элементы)\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "P4v2OUp74Zwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_csv_data(doctors_data):\n",
        "    csv_data = []\n",
        "\n",
        "    for doctor in doctors_data:\n",
        "\n",
        "        # Основная информация\n",
        "        row = {\n",
        "            'name': doctor.get('name', None),\n",
        "            'speciality': doctor.get('speciality', None),\n",
        "            'experience': doctor.get('experience', None),\n",
        "            'rating': doctor.get('rating', None),\n",
        "            'review_count': doctor.get('review_count', 0),\n",
        "            'price': doctor.get('price', None),\n",
        "            'is_kids': doctor.get('is_kids', False),\n",
        "            'is_adults': doctor.get('is_adults', False),\n",
        "            'link': doctor.get('link', None),\n",
        "        }\n",
        "\n",
        "        if doctor.get('clinics', None) is None:\n",
        "            row['clinics_count'] = 0\n",
        "            for i in range(3):\n",
        "                row[f'clinic_{i+1}_name'] = None\n",
        "                row[f'clinic_{i+1}_address'] = None\n",
        "                row[f'clinic_{i+1}_metro'] = None\n",
        "\n",
        "        else:\n",
        "            row['clinics_count'] = len(doctor.get('clinics', []))\n",
        "            # Информация о клиниках\n",
        "            clinics = doctor.get('clinics', [])\n",
        "            for i, clinic in enumerate(clinics[:3]):  # максимум 3 клиники\n",
        "                row[f'clinic_{i+1}_name'] = clinic.get('name', None)\n",
        "                row[f'clinic_{i+1}_address'] = clinic.get('address', None)\n",
        "                row[f'clinic_{i+1}_metro'] = clinic.get('metro', None)\n",
        "\n",
        "            # Заполняем пустые клиники\n",
        "            for i in range(len(clinics), 3):\n",
        "                row[f'clinic_{i+1}_name'] = None\n",
        "                row[f'clinic_{i+1}_address'] = None\n",
        "                row[f'clinic_{i+1}_metro'] = None\n",
        "\n",
        "        csv_data.append(row)\n",
        "\n",
        "    return csv_data"
      ],
      "metadata": {
        "id": "jr61Mahmqvok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_review_csv_data(doctors_data):\n",
        "    csv_data = []\n",
        "\n",
        "    for doctor in doctors_data:\n",
        "      if doctor.get('reviews', None) is None:\n",
        "        row = {\n",
        "            'doctor_name': doctor.get('name', None),\n",
        "            'doctor_link': doctor.get('link', None),\n",
        "            'rate': None,\n",
        "            'date': None,\n",
        "            'comment': None,\n",
        "            'clinic': None\n",
        "        }\n",
        "        csv_data.append(row)\n",
        "\n",
        "      else:\n",
        "        doctor_name = doctor.get('name', None)\n",
        "        doctor_link = doctor.get('link', None)\n",
        "        for review in doctor.get('reviews'):\n",
        "          row = {\n",
        "            'doctor_name': doctor_name,\n",
        "            'doctor_link': doctor_link,\n",
        "            'rate': review.get('rate', None),\n",
        "            'date': review.get('date', None),\n",
        "            'comment': review.get('comment', None),\n",
        "            'clinic': review.get('clinic', None)\n",
        "          }\n",
        "          csv_data.append(row)\n",
        "\n",
        "    return csv_data"
      ],
      "metadata": {
        "id": "TMCETlzGq8Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_dataset(csv_data, filename, folder_path):\n",
        "    csv_filename = f\"{filename}.csv\"\n",
        "    df = pd.DataFrame(csv_data)\n",
        "    file_path = os.path.join(folder_path, csv_filename)\n",
        "    df.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
        "    return df"
      ],
      "metadata": {
        "id": "KurWoM65rDtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/doctors'\n",
        "doctors_data = load_folder(folder_path)\n",
        "df = save_to_dataset(prepare_csv_data(doctors_data), 'doctors', folder_path)\n",
        "df_reviews = save_to_dataset(prepare_review_csv_data(doctors_data), 'reviews', folder_path)"
      ],
      "metadata": {
        "id": "ZpOB22Z2rKq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "KlP1-sqYrZ69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews"
      ],
      "metadata": {
        "id": "q6FH5uJbrapk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}