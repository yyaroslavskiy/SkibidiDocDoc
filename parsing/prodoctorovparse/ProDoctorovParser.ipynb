{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:04.088111Z",
     "start_time": "2025-11-12T14:40:04.081974Z"
    },
    "id": "zTACu4GZOwd_"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "# import os\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:04.310876Z",
     "start_time": "2025-11-12T14:40:04.299748Z"
    },
    "id": "SWAv_HXHLIxR"
   },
   "outputs": [],
   "source": [
    "def setup_logger(name='ProDoctorovParser'): # логгирование\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if not logger.handlers:\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        \n",
    "        file_handler = logging.FileHandler(f'{name}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log', encoding='utf-8')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:04.515024Z",
     "start_time": "2025-11-12T14:40:04.509950Z"
    },
    "id": "BD_oFEGkMULE"
   },
   "outputs": [],
   "source": [
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:04.717050Z",
     "start_time": "2025-11-12T14:40:04.708150Z"
    }
   },
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    logger.info(\"Драйверы настроены, подключение к сайту успешно.\")\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:04.896120Z",
     "start_time": "2025-11-12T14:40:04.884686Z"
    },
    "id": "rHeD9gKHO2k3"
   },
   "outputs": [],
   "source": [
    "def chrome(url):\n",
    "    logger.info(\"Настраиваем драйверы в Chrome...\")\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    \n",
    "    try:\n",
    "        browser = webdriver.Chrome(options=options)    \n",
    "        browser.get(url)\n",
    "        time.sleep(2)\n",
    "        logger.info(\"Драйверы настроены, подключение к сайту успешно.\")\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        browser.quit()\n",
    "        return soup\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка при создании драйвера: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:05.071064Z",
     "start_time": "2025-11-12T14:40:05.063364Z"
    },
    "id": "p2uHGV8ZRi8H"
   },
   "outputs": [],
   "source": [
    "def get_speciality_links():\n",
    "  soup = chrome('https://prodoctorov.ru/moskva/vrach')\n",
    "\n",
    "  specialties = []\n",
    "\n",
    "  logger.info(\"Ищем ссылки на специалистов...\")\n",
    "  for item in soup.find_all('li', class_='p-doctors-list-page__tab-item'):\n",
    "      link = item.find('a')\n",
    "      count = int(item.find('span', class_=\"p-doctors-list-page__tab-item-count p-doctors-list-page__tab-item-count_bg_none p-doctors-list-page__tab-item-count_subtitle-secondary\").text.replace('\\xa0', ''))\n",
    "      if link:\n",
    "          specialties.append([count,'https://prodoctorov.ru' + link['href']])\n",
    "  logger.info(\"Ссылки на специалистов успешно найдены.\")\n",
    "\n",
    "  return specialties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:05.244853Z",
     "start_time": "2025-11-12T14:40:05.230193Z"
    },
    "id": "oxj50_nePg_v"
   },
   "outputs": [],
   "source": [
    "def get_links_of_doctors_from_site(specialties):\n",
    "  links_from_all_pages = []\n",
    "\n",
    "  logger.info(\"Сбор ссылок на врачей...\")\n",
    "  for speciality in specialties:\n",
    "    num = 0\n",
    "    page = 0\n",
    "    while num < int(speciality[0]):\n",
    "        page+=1\n",
    "        url = speciality[1] + f'?page={page}'\n",
    "        soup = chrome(url)\n",
    "\n",
    "        doctors_data = []\n",
    "        doctor_cards = soup.find_all('a',class_='b-doctor-card__name-link text-wrap')\n",
    "        doctor_links = [card.get('href') for card in doctor_cards]\n",
    "\n",
    "        base_url = 'https://prodoctorov.ru'\n",
    "        full_doctor_links = [base_url + link for link in doctor_links]\n",
    "        links_from_all_pages += full_doctor_links\n",
    "        num += len(full_doctor_links)\n",
    "        if num >= speciality[0]:\n",
    "          break\n",
    "  logger.info(\"Все ссылки собраны успешно.\")\n",
    "\n",
    "  return links_from_all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:05.431153Z",
     "start_time": "2025-11-12T14:40:05.421869Z"
    },
    "id": "4O3njpkpE5PT"
   },
   "outputs": [],
   "source": [
    "def get_clinics(clinics):\n",
    "  clinics_info = []\n",
    "  for clinic in clinics:\n",
    "\n",
    "    clinic_info = {}\n",
    "\n",
    "    name = clinic.find('a', class_=\"text-subtitle-1 primary--text text-decoration-none\")\n",
    "    clinic_info['name'] = name.get_text(strip=True) if name else 'No value'\n",
    "\n",
    "    address = clinic.find('div', class_=\"d-flex align-center text-body-1 primary--text py-2 cursor-pointer mt-4\")\n",
    "    clinic_info['address'] = address.get_text(strip=True) if address else 'No value'\n",
    "\n",
    "    metro = clinic.find('span',{'data-qa': 'metro_name'})\n",
    "    clinic_info['metro'] = metro.get_text(strip=True) if metro else 'No value'\n",
    "\n",
    "    clinics_info.append(clinic_info)\n",
    "  return clinics_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:05.640640Z",
     "start_time": "2025-11-12T14:40:05.630067Z"
    },
    "id": "8UTPNqE1i_Qm"
   },
   "outputs": [],
   "source": [
    "def get_reviews(reviews):\n",
    "  reviews_info = []\n",
    "  for review in reviews:\n",
    "\n",
    "    review_info = {}\n",
    "\n",
    "    rate = review.find('span', class_=\"text-subtitle-2 text--text ml-1\")\n",
    "    review_info['rate'] = float(rate.get_text(strip=True)) if rate else 'No value'\n",
    "\n",
    "    date = review.find('div', class_=\"text-body-2 text-secondary--text mb-5\")\n",
    "    review_info['date'] = date.get('content') if date else 'No value'\n",
    "\n",
    "    comment = review.find('div', class_=\"b-review-card__comment text-body-1 text--text mt-2\")\n",
    "    review_info['comment'] = comment.get_text(strip=True) if comment else 'No value'\n",
    "\n",
    "\n",
    "    clinic = review.find('div', class_=\"b-review-card__address\")\n",
    "    review_info['clinic'] = clinic.get_text(strip=True) if clinic else 'No value'\n",
    "\n",
    "    reviews_info.append(review_info)\n",
    "  return reviews_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:06.044383Z",
     "start_time": "2025-11-12T14:40:06.017724Z"
    },
    "id": "211qGWBUpTur"
   },
   "outputs": [],
   "source": [
    "def get_doctors_info(link, browser):\n",
    "#     soup = chrome(link)\n",
    "    browser.get(link)\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    logger.info(\"HTML успешно получен\")\n",
    "    doctor_info = {}\n",
    "\n",
    "    name = soup.find('span', class_=\"d-block text-h5 text--text mb-2\")\n",
    "    doctor_info['name'] = name.get_text(strip=True) if name else 'No value'\n",
    "\n",
    "    doctor_info['link'] = link\n",
    "\n",
    "    speciality = soup.find('div', class_='b-doctor-intro__specs')\n",
    "    spec = ','.join([s.strip() for s in speciality.get_text(separator=',').split(',')if s.strip()]).lower()\n",
    "    doctor_info['speciality'] = spec if speciality else 'No value'\n",
    "\n",
    "    clinics = soup.find_all('div', class_=\"doctor-page-list-lpu pa-6\")\n",
    "    doctor_info['clinics'] = get_clinics(clinics) if clinics else 'No value'\n",
    "\n",
    "    price = soup.find('div', class_='text-h6')\n",
    "    if price:\n",
    "        price_text = price.get_text(strip=True)\n",
    "        price_match = re.search(r'\\d+', price_text)\n",
    "        if price_match:\n",
    "            doctor_info['price'] = float(price_match.group())\n",
    "        else:\n",
    "            doctor_info['price'] = 'No value'\n",
    "    else:\n",
    "        doctor_info['price'] = 'No value'\n",
    "\n",
    "    experience = soup.find('div', class_='text-subtitle-1')\n",
    "    if experience:\n",
    "        exp_text = experience.get_text(strip=True)\n",
    "        exp_match = re.search(r'\\d+', exp_text)\n",
    "        if exp_match:\n",
    "            doctor_info['experience'] = int(exp_match.group())\n",
    "        else:\n",
    "            doctor_info['experience'] = 'No value'\n",
    "    else:\n",
    "        doctor_info['experience'] = 'No value'\n",
    "\n",
    "    rating = soup.find('div', class_='text-h5')\n",
    "    doctor_info['rating'] = float(rating.text.strip()) if rating else 'No value'\n",
    "\n",
    "    review_count = soup.find('span', class_='ml-2')\n",
    "    doctor_info['review_count'] = float(review_count.text.strip().split()[0]) if review_count else 'No value'\n",
    "\n",
    "    reviews = soup.find_all('div', {\"itemprop\":\"review\"})\n",
    "    doctor_info['reviews'] = get_reviews(reviews) if reviews else 'No value'\n",
    "\n",
    "    doctor_info['is_kids'] = True if 'детский' in spec else False\n",
    "    if sum(list(map(lambda x: True if 'детский' not in x else False, spec.split(',')))) != 0:\n",
    "      doctor_info['is_adults'] = True\n",
    "    else:\n",
    "      doctor_info['is_adults'] = False\n",
    "    \n",
    "    logger.info(\"Данные доктора получены из HTML\")\n",
    "\n",
    "    return doctor_info\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:06.694636Z",
     "start_time": "2025-11-12T14:40:06.684469Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "kByoQR0sxfCm",
    "outputId": "63751138-cd14-469b-e556-9b9f37105e6f"
   },
   "outputs": [],
   "source": [
    "# kardiolog = get_links_of_doctors_from_site([[3343, 'https://prodoctorov.ru/moskva/kardiolog/'],[352, 'https://prodoctorov.ru/moskva/detskiy-kardiolog/']])\n",
    "# kardiologs = ','.join(kardiolog)\n",
    "# with open('onkologi.txt', 'w') as f:\n",
    "#   f.write(kardiologs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:40:06.962167Z",
     "start_time": "2025-11-12T14:40:06.951656Z"
    },
    "id": "kU4hATzorXmK"
   },
   "outputs": [],
   "source": [
    "kardiologs = open('onkologi.txt').readline().split(',')\n",
    "len(kardiologs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:41:20.401384Z",
     "start_time": "2025-11-12T14:40:07.329983Z"
    },
    "id": "-8T5I0eGMhBB"
   },
   "outputs": [],
   "source": [
    "data_kardiologs_1 = []\n",
    "\n",
    "driver = setup_driver()\n",
    "\n",
    "n = 0\n",
    "logger.info(\"Запускаем парсинг врачей...\")\n",
    "for doc in kardiologs[:50]:\n",
    "  n+=1\n",
    "  data_kardiologs_1.append(get_doctors_info(doc, driver))\n",
    "  logger.info(f\"Успешная запись информации о враче ({n}/1000).\")\n",
    "logger.info(f\"Группа обработана успешно. Сохраняем датасет.\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame.from_records(data_kardiologs_1)\n",
    "df.to_csv('data_kardiologs_0_1000.csv', index=False)\n",
    "logger.info(f\"Датасет сохранён.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hsu9sPWn4fT0"
   },
   "outputs": [],
   "source": [
    "# data_kardiologs_2 = []\n",
    "\n",
    "# n = 0\n",
    "# logger.info(\"Запускаем парсинг врачей...\")\n",
    "# for doc in kardiologs[1000:2500]:\n",
    "#   n+=1\n",
    "#   data_kardiologs_2.append(get_doctors_info(doc))\n",
    "#   logger.info(f\"Успешная запись информации о враче ({n+1000}/{1500+1000}).\")\n",
    "# logger.info(f\"Группа обработана успешно. Сохраняем датасет.\")\n",
    "\n",
    "# df = pd.DataFrame.from_records(data_kardiologs_2)\n",
    "# df.to_csv('data_kardiologs_1000_2500.csv', index=False)\n",
    "# logger.info(f\"Датасет сохранён.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8P1Wkgd3XPb"
   },
   "outputs": [],
   "source": [
    "# data_kardiologs_3 = []\n",
    "\n",
    "# n = 0\n",
    "# logger.info(\"Запускаем парсинг врачей...\")\n",
    "# for doc in kardiologs[2500:]:\n",
    "#   n+=1\n",
    "#   data_kardiologs_3.append(get_doctors_info(doc))\n",
    "#   logger.info(f\"Успешная запись информации о враче ({n+2500}/{1195+2500}).\")\n",
    "# logger.info(f\"Группа обработана успешно. Сохраняем датасет.\")\n",
    "\n",
    "# df = pd.DataFrame.from_records(data_kardiologs_3)\n",
    "# df.to_csv('data_kardiologs_2500_3695.csv', index=False)\n",
    "# logger.info(f\"Датасет сохранён.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
